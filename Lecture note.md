[TOC]

# Lecture 1

## Questions
### ä»€éº¼æ˜¯å¤šè®Šé‡åˆ†æ? ç‚ºä»€éº¼ä½¿ç”¨?
- åˆç¨± Multivariate Data Analysisï¼ŒæŒ‡æ¶‰æ‰€æœ‰åŒæ™‚åˆ†æè¤‡æ•¸å€‹è®Šæ•¸(ä¾‹å¦‚é—œæ–¼å€‹é«”çš„é‡æ¸¬)çš„çµ±è¨ˆæ–¹æ³•ã€‚
- æ‰€æœ‰è®Šæ•¸ä¸€å®šè¦æ˜¯éš¨æ©Ÿä¸”è®Šæ•¸ä¹‹é–“è¦å­˜åœ¨äº’ç›¸é—œè¯(ä¸ç„¶å°±è¦åˆ†æˆå…©å€‹å•é¡Œ)
- å€‹åˆ¥æ•ˆæ‡‰é›£ä»¥è¢«æœ‰æ„ç¾©åœ°åˆ†é–‹è©®é‡‹
- ç‚ºä»€éº¼ï¼šè§£é‡‹èˆ‡é æ¸¬ï¼›å¹«åŠ©æ±ºç­–ï¼›å‡èªªé©—è­‰


### å¤šè®Šé‡åˆ†ææ­¥é©Ÿ
1. ç‰¹å®šå‡ºæ¦‚å¿µã€èƒŒå¾Œç†è«–ï¼›æ¦‚å¿µæ¨¡å‹ä¸éœ€è¦å¤ªè¤‡é›œæˆ–æœ‰å¤ªå¤šç´°ç¯€
2. åˆ†æè¦åŠƒ
    - ä¾‹å¦‚ï¼Œéœ€è¦è‡³å°‘æˆ–å¤§æ¦‚ä»€éº¼è¦æ¨¡çš„sample sizeã€æ¥å—ä»€éº¼æ¨£å‹åˆ¥çš„è®Šæ•¸ã€ä¼°è¨ˆæ–¹æ³•ç­‰
3. underlying assumption: e.g. normality, linearity... and two more (see ppt)
4. estimate the multivariate model and assess overall model fit
    - statistical and practical significance
    - çµæœæ˜¯å¦éåˆ†åœ°å—å–®ä¸€/æ¥µå°‘æ•¸è§€æ¸¬æ‰€å½±éŸ¿?
5. Interpret the variate(s)
    - reveals multivariate relationships 
      - I.V.s: estimated coefficients 
      - variate(s) [D.V.(s)]: underlying dimensions of association
    - identify the empirical evidence of multivariate relationships in the sample data that can be generalized to the total population åœ¨å¯è¢«æ¦‚åŒ–è‡³æ¯é«”çš„è³‡æ–™ä¸­æ˜¯å¦èƒ½ç™¼ç¾/çœ‹åˆ°èˆ‡å¾—åˆ°ä¹‹å¤šè®Šé‡æ¨¡å‹ä¹‹ç¶“é©—ä¸Šçš„è­‰æ“š
6. Validate
    - è¨ºæ–·æ€§åˆ†æè©•ä¼°æ¦‚åŒ–èƒ½åŠ›(generalizability)
    - can be generalized to the population?


### å…¶ä»–å•é¡Œ
Why are scales of measurement important for data analysis?
- Each of the four scales (i.e., nominal, ordinal, interval, and ratio) provides a different type of information. ... Measurement refers to the assignment of numbers in a meaningful way, and understanding measurement scales is important to interpreting the numbers assigned to people, objects, and events.

What basic issues need to be examined when using multivariate analysis?
- Prediction of relations between variables is not an easy task. Each model has its assumptions. The most important assumptions underlying multivariate analysis are **normality, homoscedasticity, linearity**, and **the absence of correlated errors**. 
- See [Four important statistical assumptions](#four-important-statistical-assumptions)

## å¤šè®Šé‡åˆ†æ
Big Data
- Volume (é‡å¤§)
- Variety (å¤šæ¨£æ€§)ã€é«˜é€Ÿ (velocity)ã€çœŸå¯¦æ€§ (veracity)ã€å¿«é€Ÿè®Šå‹•æ€§(variability)ã€åƒ¹å€¼(value)
- æ¨£æœ¬è¶Šå¤§ï¼Œçµ±è¨ˆæ¨è«–çš„éœ€æ±‚å°±è¶Šå°‘ï¼›ç›´æ¥è™•ç†æ¯é«”ï¼Œæ²’æœ‰çµ±è¨ˆæ¨è«–çš„éœ€æ±‚(e.g., å°±ä¸ç”¨ç®¡ä¾‹å¦‚confidence levelé‚£äº›)ã€‚
- å·¥å…·ä¸»ç¾©ï¼šåªè¦èƒ½å¤ é æ¸¬ï¼Œä¸ç®¡ç‚ºä»€éº¼/åŸç†ã€‚
- ç„¡æ³•æä¾›å­¸ç†ä¸Šçš„è§£é‡‹
- è¡æ“Š
  - çµ„ç¹”æ±ºç­–èˆ‡å­¸è¡“ç ”ç©¶
  - åˆ†ææ–¹æ³•èˆ‡åˆ†æè€…: è™•ç†çœ‹ä¼¼ç„¡é™é‡çš„è³‡æ–™


è³‡æ–™åˆ†æçš„å…©æ”¯ Two distinctive approach
- Statistical/data model
  - é‡é»åœ¨è§£é‡‹
  - æ¨¡å‹åŸºæ–¼ç†è«– > åˆ†æè³‡æ–™ > æª¢é©—ç†è«–
  - çµ±è¨ˆæ¨è«–(æ¨£æœ¬æ¨æ¯é«”æ•¸é‡ç‰¹å¾µ)ä»¥åŠç”¨çµ±è¨ˆæª¢å®šæª¢é©—æ¨¡å‹çš„æ¦‚åŒ–èƒ½åŠ›
  - ç‰¹å®šæ¨¡å‹çš„å»ºç«‹: e.g. dependent variables and independent variables to be analyzed by the general linear model
- Datamining/Algorithmic model 
  - é‡é»åœ¨é æ¸¬çš„ç²¾ç¢ºåº¦
  - æ¨¡å‹åŸºæ–¼ç®—æ³•(ä¾‹å¦‚ ç¥ç¶“ç¶²è·¯ã€æ±ºç­–æ¨¹)
  - åˆ†æè³‡æ–™> å¾—åˆ°é—œä¿‚(æ¨¡å‹)
  - ä¸é‡è§£é‡‹èˆ‡çµ±è¨ˆæ¨è«–

**Also see:** æŠ•å½±ç‰‡è¡¨æ ¼!

Causal Inference å› æœé—œä¿‚
- åœ¨ä¸åšå¯¦é©—çš„æƒ…æ³ä¸‹å¾—åˆ°è¶…è¶Šçµ±è¨ˆæ¨è«–çš„ã€ŒåŸå› -å¾Œæœ(cause-effect) çš„è«–è¿°ã€

Variate
- a linear combination of variables with empirically determined weight
- $Y = W_1X_1+W_2X_2+W_3X_3+...+W_nX_n$
  - e.g., $X_1=$ income; $X_2=$ education;...

| $Y$ | $X_1$ | $X_2$ | ... | $X_n$ |
| --- | ----- | ----- | --- | ----- |
| ... | ...   | ...   | ... | ...   |
| ... | ...   | ...   | ... | ...   |
| ... | ...   | ...   | ... | ...   |

### Measurement scale
- Non-metric (qualitative) scale
  - (1st level) nominal, categorical, i.e., é¡åˆ¥çš„ã€ç„¡åº(ç·¨è™Ÿèˆ‡é †åºæˆ–é‡åŒ–å€¼ç„¡é—œ)ã€‚
  - (2nd level) ordinal, e.g., 10%-20%...; å‰10%...; é †åºä»£è¡¨æ¸¬é‡åˆ°çš„ç‰¹å¾µå¼·å¼±ï¼Œä½†ä¸èƒ½åæ˜ å¼·å¤šå°‘/å¼±å¤šå°‘ã€‚ä¾‹å¦‚ï¼šéå¸¸å–œæ­¡-å–œæ­¡-æ™®é€š-è¨å­-éå¸¸è¨å­
  - ä¸å¯è½‰æˆmetric scale
- Metric scale: numerical, quantitative
  - (3rd level) Intervalï¼šä¾‹å¦‚æº«åº¦ï¼Œæœ‰åº(æ•¸å€¼èƒ½å¤ æ¯”è¼ƒ)ã€ç­‰è·(10$^\circ$C-20$^\circ$Cå€é–“èˆ‡20$^\circ$C-30$^\circ$C)ï¼›æ²’æœ‰çµ•å°çš„é›¶(true zero value)
  - (4th level) Ratio: Having all properties that interval scales have and in addition a natural zero point. Ratio scale has absolute zero, hence does not have negative values.
  - å¯è½‰æˆNon-metric scale
- [Difference between ratio and interval scale](https://www.questionpro.com/blog/ratio-scale-vs-interval-scale/): measurements using interval scale donâ€™t provide any sense of ratio between one another. E.g., you can say 32$^\circ$C is hotter than 16$^\circ$C, but it is nonsense to say "it is twice as hot than 16$^\circ$C".
- Also see https://www.questionpro.com/blog/nominal-ordinal-interval-ratio/
  

![](fig/MeasurementScale_tree.png)


### Validity and Reliability
See [this](https://www.scribbr.com/methodology/reliability-vs-validity/) and ppt.

### TF table

![](fig/TFtable.png)
| "å‡è¨­" \ "å¯¦éš›ä¸Š"         | $H_0$ true (æ²’é—œä¿‚) | $H_0$ false (æœ‰é—œä¿‚)    |
| ------------------------- | ------------------- | ----------------------- |
| not reject $H_0$ (æ²’é—œä¿‚) | $1-\alpha$          | $\beta$ [type II]       |
| reject $H_0$ (æœ‰é—œä¿‚)     | $\alpha$ [type I]   | $1 - \beta$ **"Power"** |

> $H_0$ true: è™›ç„¡å‡è¨­æ˜¯æ­£ç¢ºçš„ï¼Œå³**æ²’æœ‰é—œä¿‚**
> $H_0$ false: è™›ç„¡å‡è¨­(æ²’æœ‰é—œä¿‚)æ˜¯éŒ¯çš„ï¼Œå³**æœ‰é—œä¿‚**
> Type I error: æ²’æœ‰é—œä¿‚èªªæˆæœ‰é—œä¿‚çš„æ©Ÿç‡
> Type II error: æœ‰é—œä¿‚èªªæˆæ²’é—œä¿‚çš„æ©Ÿç‡



### Statistical power
[â€œStatistical significance helps quantify whether a result is likely due to chance or to some factor of interestâ€](https://hbr.org/2016/02/a-refresher-on-statistical-significance)
![](fig/SampSzPower.png)
![](fig/SampSzPowerTb.png)
<!-- <center>
<img src="fig/SampSzPower.png" width=300><img src="fig/SampSzPowerTb.png" width=300>
</center> -->
- Sample Sizeå¤ªå¤§çš„æ™‚å€™ï¼Œä¸€é»å°å½±éŸ¿/å·®ç•°/è®ŠåŒ–éƒ½å¯èƒ½æœƒæ˜¯çµ±è¨ˆé¡¯è‘—ã€‚**ä¸èƒ½ç”¨æ–¼Big Data**ã€‚
- è¦è§€å¯Ÿçš„å½±éŸ¿(effect size)å¾ˆå°çš„æ™‚å€™ï¼Œå‰‡éœ€å¢åŠ Sample Sizeä»¥é”åˆ°è¶³å¤ çš„Powerã€‚$\Rightarrow$ power çš„å¢åŠ é€šå¸¸æ˜¯ sample size è®Šå¤§é€ æˆçš„ã€‚

- what is effect size?
- large sample size, what increases?
- small sample size, prone to?
- power too strong, prone to?
- power too weak, prone to?
- 


### Dependence and Interdependence 
Dependence Techniques: è®Šé‡åˆ†æˆI.V. èˆ‡è¢«è§£é‡‹çš„/æ¬²é æ¸¬çš„ D.V.
- MANOVA
  - å¤šå€‹ dependent variables: Multiple (metric) = Multiple (nonmetric)
- ANOVA
  - å–®å€‹ dependent variables: Single (metric) = Multiple (nonmetric)
- Multiple Discriminant Analysis
  - Single (nonmetric) =  multiple (metric)
  - è·Ÿcluster analysis æœ‰ç•°æ›²åŒå·¥ä¹‹å¦™ã€‚
- Multiple Regression analysis
  - single (metric) = multiple (**any**)
- çµæ§‹æ–¹ç¨‹
  - å…·æœ‰å¤šå€‹æ–¹ç¨‹å¼ï¼›æ¯å€‹æ–¹ç¨‹å¼(æ¨¡å‹)éƒ½è¦è¢«æ»¿è¶³ã€‚
  - åŒæ™‚ä¼°è¨ˆä¸åŒå‡èªªä¸‹çš„æ¨¡å‹ã€‚


Interdependence techniques: 
- åŒæ™‚åˆ†æè€ƒæ…®æ‰€æœ‰è®Šæ•¸(è®Šé‡)ï¼Œä¸å€åˆ¥I.V.èˆ‡D.V.ã€‚
- ç¯„ä¾‹ï¼š
  - Factor analysis
  - Cluster analysis

### Problems
- ä¸èƒ½å–ä»£ç†è«–çš„å»ºç«‹
- ç”¢ç”ŸæŒ‡å¼•(guidelines)

### Guidelines for multivariate analysis
- å»ºç«‹å¯¦å‹™(practical) é¡¯è‘—æ€§ï¼š(?)éœ€è¼ƒé«˜çš„ effect size
- è¿½æ±‚ç°¡ç´„(parsimony)ï¼šæ‰¾åˆ°å°‘æ•¸é—œéµçš„å› å­(è®Šæ•¸)ã€‚ç†è«–(æ¦‚å¿µæ¨¡å‹^[cpt])æ˜¯é™åˆ¶ç ”ç©¶ç¯„åœçš„é‡è¦çš„å·¥å…·ã€‚


[^cpt]: See "Strive for Model Parsimony", p35 of Lecture Ch1

### Validate Your Result
è¶Šè¤‡é›œçš„æ¨¡å‹(é—œä¿‚/interrelationships)ï¼Œå¸¸å¸¸æ„å‘³è‘—é€™å€‹æ¨¡å‹åªé©åˆç‰¹å®šçš„æ¨£æœ¬ç¾¤ï¼Œé›£ä»¥æ¦‚åŒ–(generalizable)ã€‚
  - æ”¹å–„ï¼šå¢åŠ æ¯å€‹ä¼°è¨ˆçš„è§€æ¸¬è³‡æ–™ã€åˆ†å‰²è³‡æ–™é›†ã€...

"åˆ†ææ¨£æœ¬å›æ¨æ¯é«”"ï¼š
- ç›®æ¨™æ˜¯å»ºç«‹ä¸€å€‹èƒ½æè¿°æ¯é«”(the population as a whole)çš„æ¨¡å‹(model)ï¼Œä¸¦éæ‰¾åˆ°"best fit"ã€‚
- æ¨£æœ¬éœ€å°æ¯é«”è¦æœ‰ä»£è¡¨æ€§ã€‚




### statistical and practical significance
[Whatâ€™s the difference between statistical and practical significance?](https://www.scribbr.com/frequently-asked-questions/statistical-significance-vs-practical-significance/)

While statistical significance shows that an effect exists in a study, practical significance shows that the effect is large enough to be meaningful in the real world.

Statistical significance is denoted by p-values whereas practical significance is represented by effect sizes.

# Lecture 2
## Questions
What are the principal aspects of data that need to be examined?


What approaches would you use in examining each aspect?
- preliminary understanding of your data: 
  - univariate profiling (shape/distribution)
  - bivariate profiling 
    - relationships between variables
    - group differences (æ ¹æ“šæŸä¸€è®Šæ•¸åˆ†ç¾¤ï¼Œçœ‹å„ç¾¤é«”çš„çµ±è¨ˆå€¼ã€‚ä¾‹å¦‚ åˆ†ç”·å¥³çœ‹æˆç¸¾)
- graphical examination: see shape using histogram; see relationships using scatterplot
- identify and evaluate missing values
- identify and deal with outliers
- check statistical assumptions
## Examine your data

### Missing data
key:
- random or systematic
- researcher's concern:
  - patterns and relationships underlying
  - maintain as close to the original distribution when any remedy is applied

impact:
- reduced sample size
- distort results


#### Four steps:
##### 1. the type and levels of missingness
ignorable missing data:
- expected and part of research design
- the missing data process is random
- censored data (é‚„æ²’è¾¦æ³•è¢«è§€æ¸¬åˆ°çš„ï¼Œä¾‹å¦‚é—œæ–¼å­˜æ´»ç‡çš„è³‡æ–™æ”¶é›†)

not ignorable:
- known process
  - procedural (e.g., data management)
- unknown process
  - å—è©¦è€…å€‹äººå› ç´ 


Three levels
- item level (ç¨ç«‹è®Šæ•¸çš„éºå¤±e.g., æŸäººæœ‰å¹¾é¡Œæœªå›ç­”å°è‡´)
- construct level (e.g., ä¸çŸ¥é“æˆ–æ‹’ç­”)
- personal level: é—œæ–¼å—è©¦è€…æ„é¡˜æˆ–å›ç­”ä¹‹èƒ½åŠ› (e.g. é¡˜æ„å¡«ç­”è€…éƒ½æ˜¯ç¸¾æ•ˆè¼ƒå¥½çš„ã€å¡«ç­”ä¸èª å¯¦)


##### 2. extent of missing data (è³‡æ–™ç¼ºæçš„ç¨‹åº¦)
åŸºæœ¬å•é¡Œï¼š
- ç¨‹åº¦æ˜¯å¦è¼•å¾®åˆ°å³ä½¿ç¼ºå¤±å€¼ééš¨æ©Ÿä¹Ÿä¸å½±éŸ¿çµæœ?

levels of analysis (ç™¾åˆ†æ¯”)
- by variable (å¾ç›´è¡Œçœ‹ç¼ºå€¼æ¯”ä¾‹)
- by case (å¾æ©«åˆ—çœ‹ç¼ºå€¼æ¯”ä¾‹)

Guide:
- 10% ä»¥ä¸‹
- è™•æ²»æ‰‹æ®µ(remedy)è¦ç¢ºä¿sample sizeè¶³å¤ 
- é€šå¸¸ç¼º D.V. å°±ç›´æ¥æ•´ç­†åˆªæ‰
- è‹¥ç¼º I.V.ï¼Œè¦ç¢ºä¿æœ‰å…¶ä»–å¯æ›¿ä»£çš„æŒ‡æ¨™(åæ˜ åŸæœ¬è®Šæ•¸çš„æ„åœ–ï¼Œä¾‹å¦‚æœ‰4é¡Œéƒ½æ˜¯è©•ä¼°åŒä¸€é …æŒ‡æ¨™ï¼Œå‰‡ä¸€é¡Œç¼ºç­”å¯æ¥å—)
- åˆ†æåˆªæˆ–ä¸åˆªå°çµæœçš„å½±éŸ¿ã€‚

##### 3. Diagnose the randomness 
ç¼ºå¤±å€¼çš„éš¨æ©Ÿæ€§è³ª
- MAR: ç¼ºå€¼èˆ‡ X ç›¸ä¾ï¼Œä½†èˆ‡ Y ç„¡é—œï¼›ç„¡biasã€‚ä¾‹å¦‚åˆ†æ X=ä¼æ¥­è¦æ¨¡ èˆ‡ Y=ç¸¾æ•ˆ çš„é—œä¿‚ï¼Œå°ä¼æ¥­ç¼ºå€¼åš´é‡ï¼Œé‚„æ˜¯å¯ä»¥é€²è¡Œæœ‰æ„ç¾©çš„åˆ†æ(å¯å‰”é™¤å°ä¼æ¥­)ï¼Œä½†åˆ†æçµæœåƒ…é©ç”¨å¤§ä¼æ¥­ã€‚
- MCAR: å®Œå…¨éš¨æ©Ÿ :thumbsup:
- NMAR (Not missing at random): æœ‰biasã€‚ e.g. æ•´ä»½æ‹’ç­” e.g. ç¸¾æ•ˆå·®çš„å…¬å¸ç¼ºå€¼åš´é‡(ä¸é¡˜æ„å¡«ç­”)ã€‚

è¨ºæ–·ï¼š
- t-test: æ ¹æ“šæ˜¯å¦ç¼ºå€¼åˆ†é¡ï¼Œç„¶å¾Œæ¸¬è©¦å…¶ä»–è®Šæ•¸ã€‚ä¾‹å¦‚ï¼Œç¼ºX1çš„ä¸€çµ„ï¼Œæ²’ç¼ºX1çš„ä¸€çµ„ï¼Œçœ‹å…¶ä»–è®Šæ•¸(X234...)åˆ†å¸ƒæ˜¯å¦æœ‰å·®ç•°ã€‚è‹¥æœ‰ï¼ŒMARï¼›è‹¥ç„¡ï¼ŒMCARã€‚
- Little's MCAR test "æ˜¯ä¸æ˜¯è¶³å¤ æ¥è¿‘MCAR"

##### 4. Select the imputation method

ç­–ç•¥ï¼š
- MCAR: ç›´æ¥åˆªæ‰æœ‰ç¼ºå€¼å¾—è³‡æ–™ ğŸ‘Œ
- æ•´ç­†(case)åˆªæ‰æˆ–åˆªæ‰æŸè®Šæ•¸(variable): ä¾æ“šç†è«–è€ƒé‡ä»¥åŠæ†‘ç¶“é©—
- ä¼°è¨ˆç¼ºå¤±å€¼: imputation 

è£œç¼ºå€¼çš„æ–¹æ³•
- case substitution
- mean substitution: ç”¨å¹³å‡å€¼å–ä»£ï¼›é€ æˆé›¢æ•£ç¨‹åº¦è¢«ä½ä¼°
- deck imputation: ç”¨æ—¢æœ‰(hot)æˆ–å¤–éƒ¨(cold)å’Œç¼ºå€¼é¡ä¼¼çš„å–ä»£
- regression imputation: æŠŠç¼ºå€¼æ ¹æ“šå›æ­¸ç·šè£œä¸Šï¼›å¼·åŒ–åŸæœ‰é—œä¿‚ã€ä½ä¼°é›¢æ•£ç¨‹åº¦
- model-based procedure: see [Handling â€œMissing Dataâ€ Like a Pro](https://towardsdatascience.com/handling-missing-data-like-a-pro-part-3-model-based-multiple-imputation-methods-bdfe85f93087)

æ–¹æ³•åå¥½
- 10%ä»¥ä¸‹ï¼šåˆªé™¤å…¨éƒ¨ç¼ºå€¼
- 10-20%
  - MCAR: hot deck case substitution & regression methods are preferred
  - MAR: model-based methods are necessary
- over 20%
  - MCAR: regression methods are preferred
  - MAR: model-based methods
- In general, model-based methods are preferred for both MCAR and MAR, though for MCAR any imputation methods produce unbiased results.


### Outlier
- a unique combination or extraordinary value
- is the observation/response representative of the population? é€™å€‹è§€æ¸¬æ˜¯çœŸçš„å‡çš„

ä¸€èˆ¬ä¾†èªª(ppt p43)
- univariate: 2.5 std
- bivariate: çœ‹é—œä¿‚æ˜¯å¦ç‰¹åˆ¥(ä¾‹å¦‚èº«é«˜é«”è¼•)ï¼›scatterplot w/ confidence intervals
- multivariate methods: D2/df measure should be very conservative (0.005 or 0.001)
- D2: multivariate detection

Dealing with outliers
- é™¤éè­‰æ˜æœ‰èª¤ï¼Œä¸ç„¶ä¿ç•™
- åŒ…å«/ä¸åŒ…å«outlieråˆ†åˆ¥ç”¢ç”Ÿçµæœ

#### impact
- çœŸå¯¦çš„ä»é ˆç´å…¥
- æ‰­æ›²çµæœï¼›è¡æ“Šæ¦‚åŒ–èƒ½åŠ›
- å¸¸ç”¨æ–¹æ³•ã€Œè‡ªæˆ‘è¨­é™ã€(e.g. å› ç‚ºç„¡æ³•è¾¨çœŸå‡ï¼Œä¸€å¾‹å‰”é™¤)ï¼š"æˆ‘çš„ç ”ç©¶çµæœä¸¦ä¸åŠæ–¼è¢«æ’é™¤çš„å°‘æ•¸ç¾¤é«”"
### dummy variable
- non-metric I.V.
- two or more levels that are coded 0 and 1

e.g. 
| Category  | X1  | X2  |
| --------- | --- | --- |
| Physician | 1   | 0   |
| Attorney  | 0   | 1   |
| Professor | 0   | 0   |
### Four important statistical assumptions
Normality (å¸¸æ…‹æ€§)
- è‹¥æ˜¯è³‡æ–™å‘ˆç¾å¸¸æ…‹åˆ†é… (normal distribution)ï¼Œå‰‡èª¤å·®é …ä¹Ÿæœƒå‘ˆç¾åŒæ¨£çš„åˆ†é…
- çµ±è¨ˆæ¨è«–(å¾æ¨£æœ¬åˆ°æ¯é«”)çš„åŸºç¤

Homoscedasticity/equality of variance (èª¤å·®é …çš„è®Šç•°æ•¸ç›¸ç­‰)
- è‡ªè®Šæ•¸çš„èª¤å·®é …é™¤äº†éœ€è¦å‘ˆç¾å¸¸æ…‹æ€§åˆ†é…å¤–ï¼Œå…¶è®Šç•°æ•¸ä¹Ÿéœ€è¦ç›¸ç­‰ï¼Œè®Šç•°æ•¸çš„ä¸ç›¸ç­‰(heteroscedasticity)æœƒå°è‡´è‡ªè®Šæ•¸ç„¡æ³•æœ‰æ•ˆçš„ä¼°è¨ˆæ‡‰è®Šæ•¸
> æ®˜å·®å€¼çš„åˆ†é…å…·æœ‰ç›¸åŒè®Šç•°æ•¸(common variance)ï¼›äº¦å³ï¼Œæ¯å€‹æ®˜å·®å€¼æ‰€æ§‹æˆçš„æ¬¡æ•¸åˆ†é…éƒ½å…·æœ‰ç›¸åŒçš„è®Šç•°æ•¸ï¼Œé€™é …å‡å®šç¨±ä½œã€Œç­‰åˆ†æ•£æ€§ã€(homoscedasticity)

Linearity
- ä¾‹å¦‚å–®ä½è‡ªè®Šæ•¸è®ŠåŒ–çš„æ‡‰è®Šæ•¸è®ŠåŒ–æ˜¯å›ºå®šçš„(å³æ–œç‡ç‚ºå¸¸æ•¸)

Non-correlated errors èª¤å·®é …çš„ç¨ç«‹æ€§(interdependence of error terms)
- è‡ªè®Šæ•¸çš„èª¤å·®é …ï¼Œç›¸äº’ä¹‹é–“æ‡‰è©²æ˜¯ç¨ç«‹çš„ï¼Œä¹Ÿå°±æ˜¯èª¤å·®é …èˆ‡èª¤å·®é …ä¹‹é–“æ²¡æœ‰ç›¸äº’é—œä¿‚


# Lecture 3
## Question
What is exploratory factor analysis
- examine the interrelationship among a large number of variables
- common underlying dimensions as factors
- a summarization and data reduction technique
- an interdependence techniques (see [L1](#dependence-and-interdependence))

## Terms
### æ¢ç´¢æ€§èˆ‡é©—è­‰æ€§
æ¢ç´¢æ€§(exploratory)ï¼šç”±è³‡æ–™å‘Šè¨´æˆ‘å€‘æ¶æ§‹
é©—è­‰æ€§(confirmatory)ï¼šæ¸¬è©¦çœ‹çœ‹åŸå…ˆè¨­æƒ³ä¹‹æ¶æ§‹(å‡èªª)æ˜¯å¦ç¬¦åˆç¾å¯¦(è³‡æ–™)

### common & unique variance
common variance (C.V.)
- èˆ‡åŒä¸€å€‹factor ä¸‹çš„å…¶ä»–è®Šæ•¸å…±äº«çš„æŸå€‹è®Šæ•¸çš„variance
unique variance (U.V.)
- specific variance
- error variance


æ¸¬é‡èª¤å·®å¤§ï¼ŒC.V.å°ï¼ŒU.V.å¤§

### factor matrix of loadings
- factor matrix of loadings has loadings of every variable on every factor extracted
- example of factor matrix
  |  |F1|F2|F3|
  |--|--|--|--|
  |X1|  |  |  |
  |X2|  |  |  |
  |X3|  |  |  |


- cross loading (é ˆé¿å…): a variable has high loadings on several factors

Identifying cross-loadings:
- used squared loadings (ä¸Šè¡¨**loadingå€¼çš„å¹³æ–¹ï¼Œå³ç‚ºvariance**)
- squared loadings çš„æ¯”ä¾‹(Ratio): æ¯æ©«åˆ—æœ€å¤§çš„å…©å€‹å€¼ç›¸é™¤
- Ratio 1.0-1.5: problematic
- Ratio 1.5-2.0: potential cross-loading, å¯è©¦è‘—åˆªé™¤è©²è®Šæ•¸
- Ratio >2     :      GOOD :thumbsup:

### communalities
Communalityï¼šæ¯å€‹factorå„ä¸€å€‹ï¼›æ•´é«”ä¹Ÿä¸€å€‹
- factor solution å°å„è®Šæ•¸çš„è®Šç•°é‡(variance)
- sum of the squared loadings across all retained factors


### surrogate; summated scale; factor scores
surrogate (ä»£ç†è®Šæ•¸)
- ğŸ‘ simple and easy to interpret
- ğŸ‘ prone to error
- ğŸ‘ ç„¡æ³•è¡¨ç¾æ‰€æœ‰é¢å‘

summated scale
- e.g. mean from high-loading vars on the factor
- a compromise between surrogate and factor scores
- ğŸ‘ easily replicated across studies
- ğŸ‘ å¯è¡¨ç¾å¤šé‡é¢å‘
- ğŸ‘ ä¸ä¸€å®šå‚ç›´

factor scores
- ğŸ‘ best for complete data reduction
- ğŸ‘ represents all vars. loadings on the factor
- ğŸ‘ å¯è¡¨ç¾å¤šé‡é¢å‘
- ğŸ‘ difficult to interpret
- ğŸ‘ ç„¡æ³•çµåˆåˆ¥çš„å•å·/ç ”ç©¶

## Exploratory Factor analysis (EFA)
### çµæœï¼šdata summarization and data reduction
data summarization:
- describe the data in a much **smaller number of concepts** than original individual variables

data reduction:
- factor score or summated scale for each factor



### æ–¹æ³•èˆ‡è¨­è¨ˆ
Correlation matrix -> ç›¸é—œä¿‚æ•¸é«˜æ–¼ç‰¹å®šæ•¸å€¼(e.g. 0.7)ç‚ºåŸºæº–åˆ†ç¾¤
- ä¾‹å¦‚ï¼Œå‘³é“ã€æº«åº¦ã€æ–°é®®åº¦ç›¸é—œæ€§é«˜ï¼Œæ­¸é¡ç‚ºã€Œé£Ÿç‰©å“è³ªã€çš„å› å­ä¹‹ä¸‹ã€‚

ä¸€èˆ¬ä¾†èªªï¼š
- åŸºæœ¬ä¸Šä½¿ç”¨metric variables
  - for nonmetric data: specialized methods exist for dummy variables
- æ¯å€‹å› ç´ è‡³å°‘5å€‹è®Šæ•¸
- è§€æ¸¬æ•¸é‡(observations)å¿…é ˆå¤§æ–¼è®Šæ•¸(variables)æ•¸é‡(å»¢è©±)
- è‡³å°‘5æœ€å¥½10 observations per variable
- correlation è‡³å°‘ 0.3

Multicollinearity 
- Bartlett's test of sphericity: sig. < 0.05 å‰‡è®Šæ•¸ä¹‹é–“çš„é—œè¯æ€§è¶³ä»¥é€²è¡Œæ¢ç´¢å¼å› ç´ åˆ†æ
- Measure of sampling adequacy (MSA): KMO value > 0.5 for both overall test and each individual variable

Extraction decisions
- Principal components analysis
  - using when data reduction is a primary concern
  - extract both common & unique variance
- Common factor analysis
  - best for well-specified theoretical applications
  - extract common variance; exclude unique variance
  - to identify latent constructs (æ§‹å¿µã€æŠ½è±¡çš„æ¦‚å¿µ) or dimensions
### Seven stages

Stage 1: Objective ç›®æ¨™
- æ¢ç´¢æ€§æˆ–é©—è­‰æ€§? (CFA or EFA?)
Stage 2: Designing
- how the var measured
- how many vars should be included
Stage 3: Assumptions
- correlation > 0.3çš„è®Šæ•¸æ•¸é‡?
Stage 4: Deriving factors & overall fit
- number of factors
Stage 5: Interpretation
- rotation of factors
Stage 6: validation
- è³‡æ–™æ‹†æˆå…©éƒ¨åˆ†ï¼Œå°‹æ±‚é©—è­‰å¼åˆ†æä¾‹å¦‚çµæ§‹æ–¹ç¨‹æ¨¡å‹
Stage 7: additional use of EFA results
- ä»£ç†è®Šæ•¸ã€summated scaleã€factor scores

### R factor analysis?

### Q factor analysis?

### The number of factors?
Stopping rules 
- a priori criterion: ç ”ç©¶è€…è‡ªå·±çŸ¥é“æœ‰å¹¾å€‹å› ç´ 
- latent root criterion (Kaiser rule):
  - latent root or eigenvalues $\geq 1$ are considered significant (æ¯å€‹factor éƒ½æœ‰ä¸€å€‹eigenvalue)
  - most commonly used; applicable to **principal component analysis**
  - less accurate with small number of vars.
- percentage of variance 
- scree test: æ–°å¢factor æ•¸é‡ä¹Ÿå¹¾ä¹ä¸æ”¹è®Š eigenvalue
  - the amount of common variances: factors before inflection point

Decision on the number of factors:
- several stopping criteria
- eigenvalue > 1.0
- predetermined number of factors
- percentage of variance > 60%
- the amount of common variances: factors before inflection point
- alternative solutions: e.g. one more or one less factor
### rotation of factors/factor loadings
ç›®æ¨™æ˜¯simple structure: 
- each var. has a high loading on one factor only. (å¦‚æœä¸€è®Šæ•¸(ä¸€é¡Œ)å’Œå¤šå› ç´ éƒ½é«˜ç›¸é—œï¼Œå‰‡åƒåœ¾é¡Œ)
- each factor has high loadings for only one subset of items


rotation of factors
- orthogonal rotation (90 $^\circ$; factors are independent)
- oblique rotation (factors can be dependent to each other)
- æ—‹è½‰å¾Œï¼Œå¾ factor loading çœ‹è®Šæ•¸èˆ‡å› ç´ ä¹‹ç›¸é—œæ€§ (loading è¶Šå¤§è¶Šç›¸é—œï¼›è·é›¢è¶Šè¿‘è¶Šç›¸é—œ)

loading is significant?
- minimal level $\pm 0.3 - 0.4$
- practically sig. $\geq\pm 0.5$
- well-defined structure $\geq\pm 0.7$
- sample size è¶Šå°ï¼Œå°loading çš„è¦æ±‚å°±è¶Šé«˜

five steps
- examine the [factor matrix of loadings](#factor-matrix-of-loadings)
- identify significant loadings for each var (é€ä¸€æŸ¥çœ‹æ‰€æœ‰è®Šæ•¸å„è‡ªå°å“ªä¸€å€‹å› ç´ ç›¸é—œæ€§æœ€é«˜)
- assess [communalities](#communalities)
- re-specify model if needed: e.g. no significant loadings; communality is too low; cross-loading
- label factors

Identifying cross loading
- 
### additional use of factor analysis

### limitations